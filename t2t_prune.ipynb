{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802cd0c4-158a-4993-9467-87f551703db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/featurize/work/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adopt transformer encoder for tokens-to-token\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from models.t2t import T2T_ViT\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "model = T2T_ViT(img_size=32, num_classes=100,num_heads=4,depth=12, drop_path_rate=0.1).cuda()\n",
    "model.eval()  \n",
    "\n",
    "\n",
    "\n",
    "image_path = \"car.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "x = transform(image).unsqueeze(0).cuda()\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f3dbab-6840-4de9-bc08-bab54b4a9d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['query_head.decoder_blocks.0.self_attn.in_proj_weight', 'query_head.decoder_blocks.0.self_attn.in_proj_bias', 'query_head.decoder_blocks.0.self_attn.out_proj.weight', 'query_head.decoder_blocks.0.self_attn.out_proj.bias'], unexpected_keys=['query_head.norm.weight', 'query_head.norm.bias', 'query_head.decoder_blocks.0.fc1.weight', 'query_head.decoder_blocks.0.fc1.bias', 'query_head.decoder_blocks.0.fc2.weight', 'query_head.decoder_blocks.0.fc2.bias'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"best-t2t.pth\")\n",
    "\n",
    "model_weights = checkpoint[\"model_state_dict\"]\n",
    "\n",
    "model_weights = {k.replace(\"module.\", \"\"): v for k, v in model_weights.items()}\n",
    "\n",
    "model.load_state_dict(model_weights, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090ae5a1-24a7-4629-a9f0-7682cbe5c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_entropy(tensor):\n",
    "   \n",
    "    tensor = F.softmax(tensor, dim=-1) \n",
    "    entropy = -torch.sum(tensor * torch.log(tensor + 1e-9), dim=-1)  \n",
    "    return entropy.mean().item()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ead772-a2f0-49a7-b847-2ea2f851c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn(module, input, output, entropies):\n",
    "   \n",
    "\n",
    "    B, N, C = input[0].shape  # B: batch size, N: number of tokens, C: channels\n",
    "    try:\n",
    "        # Adjust the way we handle the qkv computation\n",
    "        qkv = module.qkv(input[0])  # Directly compute QKV without reshaping\n",
    "        #print(f\"QKV shape: {qkv.shape}\")  \n",
    "        \n",
    "        # Split the qkv tensor directly\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        #print(f\"Q shape: {q.shape}, K shape: {k.shape}, V shape: {v.shape}\") \n",
    "\n",
    "       \n",
    "        attn_matrix = (q @ k.transpose(-2, -1)) / (C // 3) ** 0.5\n",
    "        attn_matrix = attn_matrix.softmax(dim=-1) \n",
    "\n",
    "       \n",
    "        entropy = compute_entropy(attn_matrix)\n",
    "        \n",
    "       \n",
    "        if not isinstance(entropy, torch.Tensor):\n",
    "            entropy = torch.tensor(entropy, dtype=torch.float32)\n",
    "\n",
    "        entropies.append(entropy.detach().cpu().numpy()) \n",
    "    except Exception as e:\n",
    "        print(f\"QKV computation error: {e}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f33b68-c17e-45e6-b5ab-b1787a6674fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook function used to gather attention entropy and gradients\n",
    "def compute_block_metrics(model, input_tensor, criterion, target):\n",
    "    entropies, gradient_norms = [], []\n",
    "\n",
    "    hooks = []\n",
    "    for name, module in model.named_modules():\n",
    "        #if isinstance(module,Attention)and 'blocks' in name:\n",
    "        if \"blocks\" in name and type(module).__name__ == \"Attention\":\n",
    "            hooks.append(module.register_forward_hook(lambda module, input, output: hook_fn(module, input, output, entropies)))\n",
    "\n",
    "    \n",
    "    output = model(input_tensor)  \n",
    "\n",
    "   \n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "   \n",
    "    for block in model.blocks:  \n",
    "        grad_norm = sum(torch.norm(param.grad).item() for param in block.parameters() if param.grad is not None)\n",
    "        gradient_norms.append(grad_norm)\n",
    "\n",
    "    \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    return np.array(entropies), np.array(gradient_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f828e1c5-81a9-421a-9256-b58a1dbec10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_t2t(model, input_tensor, criterion, target, k=1.0):\n",
    "   \n",
    "    attention_entropies, gradient_norms = compute_block_metrics(model, input_tensor, criterion, target)\n",
    "    print(\"Attention Entropies:\", attention_entropies)\n",
    "    print(\"Gradient Norms:\", gradient_norms)\n",
    "\n",
    "    \n",
    "    mean_entropy, std_entropy = np.mean(attention_entropies), np.std(attention_entropies)\n",
    "    mean_grad, std_grad = np.mean(gradient_norms), np.std(gradient_norms)\n",
    "\n",
    "    T_entropy = mean_entropy - k * std_entropy\n",
    "    T_grad = mean_grad - k * std_grad\n",
    "    print(\"T_entropy:\",T_entropy)\n",
    "    print(\"T_grad:\",T_grad)\n",
    "\n",
    "   \n",
    "    prune_mask = (attention_entropies < T_entropy) | (gradient_norms < T_grad)\n",
    "    print(prune_mask)\n",
    "\n",
    "    \n",
    "    block_idx = 0\n",
    "    for layer_idx, layer in enumerate(model.blocks):  \n",
    "        if prune_mask[block_idx]: \n",
    "           \n",
    "            model.blocks[layer_idx] = torch.nn.Identity()  \n",
    "            print(f\"Pruning Block {block_idx} in Layer {layer_idx}\")  \n",
    "        block_idx += 1\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c59fb2-125d-4485-838a-16a62b6b9452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Entropies: [4.172654  4.171084  4.1708627 4.1707306 4.1712217 4.1710362 4.171399\n",
      " 4.172064  4.1728396 4.1726694 4.17182   4.171971 ]\n",
      "Gradient Norms: [18.97220428 13.66780362 10.21212132  8.30563916  7.57110652  5.90074862\n",
      "  5.48550645  4.84765517  4.62953659  4.09240712  3.70700439  3.86960079]\n",
      "T_entropy: 4.17098034278024\n",
      "T_grad: 3.1460474519318584\n",
      "[False False  True  True False False False False False False False False]\n",
      "Pruning Block 2 in Layer 2\n",
      "Pruning Block 3 in Layer 3\n",
      "T2T_ViT(\n",
      "  (tokens_to_token): T2T_module(\n",
      "    (soft_split0): Unfold(kernel_size=(3, 3), dilation=1, padding=(1, 1), stride=(2, 2))\n",
      "    (soft_split1): Unfold(kernel_size=(3, 3), dilation=1, padding=(1, 1), stride=(2, 2))\n",
      "    (attention1): Token_transformer(\n",
      "      (norm1): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=27, out_features=192, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (spt): PatchShifting()\n",
      "    (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
      "    (project): Linear(in_features=576, out_features=256, bias=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.009)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2-3): 2 x Identity()\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.036)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.045)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.055)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.064)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.073)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.082)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.091)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.100)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (query_head): QueryHead(\n",
      "    (query_embed): Embedding(1, 256)\n",
      "    (decoder_blocks): Sequential(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (multi_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (head): Linear(in_features=256, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.losses import LabelSmoothingCrossEntropy\n",
    "target = torch.tensor([19], dtype=torch.long).cuda() \n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "\n",
    "\n",
    "\n",
    "pruned_model = prune_t2t(model, x, criterion, target, k=1.0)\n",
    "print(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ab4a3-5743-4ba5-9b4e-6a5eea634740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ab4df-342a-4063-8dfa-417490ee6675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
