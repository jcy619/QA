{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981408af-10c5-4375-ae34-d7433bcc42fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/featurize/work/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from models.swin import SwinTransformer\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "depths = [2,6,4]\n",
    "num_heads = [3,6,12]\n",
    "mlp_ratio = 2\n",
    "window_size = 4\n",
    "\n",
    "model=SwinTransformer(img_size=32,embed_dim=96,window_size=window_size,drop_path_rate=0.1,\n",
    "                      patch_size=2,mlp_ratio=mlp_ratio,depths=depths,num_heads=num_heads,num_classes=100,\n",
    "                      is_SPT=False, is_LSA=False).cuda()\n",
    "\n",
    "model.eval()  \n",
    "\n",
    "\n",
    "image_path = \"car.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "x = transform(image).unsqueeze(0).cuda()\n",
    "print(x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e72de94-885e-4900-8e2d-332189be3a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"best-swin.pth\")\n",
    "\n",
    "model_weights = checkpoint[\"model_state_dict\"]\n",
    "\n",
    "#delete \"module.\" \n",
    "model_weights = {k.replace(\"module.\", \"\"): v for k, v in model_weights.items()}\n",
    "\n",
    "model.load_state_dict(model_weights, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b14d55-ecdc-4db6-804e-90517c713578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def compute_entropy(tensor):\n",
    "   \n",
    "    tensor = F.softmax(tensor, dim=-1) \n",
    "    entropy = -torch.sum(tensor * torch.log(tensor + 1e-9), dim=-1)  \n",
    "    return entropy.mean().item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac91e1d-25e5-46f1-9bff-10ca3da68419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_block_metrics(model, input_tensor, criterion, target):\n",
    "    entropies, gradient_norms = [], []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        entropy = compute_entropy(output)\n",
    "        entropies.append(entropy)\n",
    "\n",
    "    hooks = []\n",
    "    for layer in model.layers:  \n",
    "        if hasattr(layer, \"blocks\"):  \n",
    "            for block in layer.blocks: \n",
    "                hooks.append(block.register_forward_hook(hook_fn))\n",
    "\n",
    "  \n",
    "    output = model(input_tensor) \n",
    "\n",
    "   \n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "   \n",
    "    gradient_norms = []\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, \"blocks\"):\n",
    "            for block in layer.blocks:\n",
    "                grad_norm = 0.0\n",
    "                for param in block.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        grad_norm += torch.norm(param.grad).item()\n",
    "                gradient_norms.append(grad_norm)\n",
    "\n",
    "    \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    print(\"entropies\",entropies)\n",
    "    print(\"gradient_norms\",gradient_norms)\n",
    "\n",
    "    return np.array(entropies), np.array(gradient_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8fc956f-6893-45b8-b5f9-6db85bd2940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropies [4.445015907287598, 4.449002265930176, 5.062499046325684, 5.0653815269470215, 5.02440071105957, 4.959166049957275, 4.834014892578125, 4.724241733551025, 5.688312530517578, 5.625767707824707, 5.506977081298828, 5.411611557006836]\n",
      "gradient_norms [55.633842304348946, 41.452643886208534, 39.26008752733469, 40.059071816504, 39.80225479602814, 36.138844415545464, 35.21963840723038, 27.96538368612528, 73.30160504579544, 69.61833009123802, 79.04520133137703, 81.44851377606392]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.losses import LabelSmoothingCrossEntropy\n",
    "target = torch.tensor([29], dtype=torch.long).cuda() \n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "attention_entropies,gradient_norms= compute_block_metrics(model, x, criterion, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258954b0-746b-4f3e-aaa6-ab00ddb41a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_entropy: 4.661746839141438\n",
      "T_grad: 33.20842826505502\n",
      "prune_mask: [ True  True False False False False False  True False False False False]\n"
     ]
    }
   ],
   "source": [
    "k = 1.0\n",
    "mean_entropy, std_entropy = np.mean(attention_entropies), np.std(attention_entropies)\n",
    "mean_grad, std_grad = np.mean(gradient_norms), np.std(gradient_norms)\n",
    "\n",
    "T_entropy = mean_entropy - k * std_entropy\n",
    "T_grad = mean_grad - k * std_grad\n",
    "print(\"T_entropy:\",T_entropy)\n",
    "print(\"T_grad:\",T_grad)\n",
    "\n",
    "prune_mask = (attention_entropies < T_entropy) | (gradient_norms < T_grad)\n",
    "print(\"prune_mask:\",prune_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8215e-fb5c-4136-bf95-7a22cf3f1d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
