{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981408af-10c5-4375-ae34-d7433bcc42fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "Attention(\n",
      "  (attend): Softmax(dim=-1)\n",
      "  (to_qkv): Linear(in_features=192, out_features=576, bias=False)\n",
      "  (to_out): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from models.vit_qa import ViT\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "model = ViT(img_size=32,patch_size=4,num_classes=100,dim=192,\n",
    "           mlp_dim_ratio=2,depth=9,heads=12,dim_head=192//12,stochastic_depth=0.1).cuda()\n",
    "\n",
    "model.eval() \n",
    "\n",
    "\n",
    "image_path = \"car.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "x = transform(image).unsqueeze(0).cuda()\n",
    "print(x.shape)\n",
    "blocks = model.transformer.layers \n",
    "print(blocks[0][0].fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e72de94-885e-4900-8e2d-332189be3a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"best-vit.pth\")\n",
    "\n",
    "model_weights = checkpoint[\"model_state_dict\"]\n",
    "\n",
    "model_weights = {k.replace(\"module.\", \"\"): v for k, v in model_weights.items()}\n",
    "\n",
    "model.load_state_dict(model_weights, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca1c58f-275d-478d-82f8-fc9346e51970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention_entropy(attn_weights):\n",
    "\n",
    "    attn_weights = attn_weights.mean(dim=1)  \n",
    "    entropy = -torch.sum(attn_weights * torch.log(attn_weights + 1e-6), dim=-1)\n",
    "    return entropy.mean().item()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd195856-beab-47a1-82f8-7f8d1bbac966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch Embedding shape: torch.Size([1, 64, 192])\n",
      "attention_entropies: [4.099283218383789, 4.120974540710449, 4.093417167663574, 4.044940948486328, 4.042279243469238, 3.7835772037506104, 3.8343920707702637, 4.019201278686523, 4.102091312408447]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attention_entropies = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = model.to_patch_embedding(x) \n",
    "    print(f\"Patch Embedding shape: {tokens.shape}\")  \n",
    "\n",
    "    for i, block in enumerate(blocks):\n",
    "   \n",
    "        attention_layer = block[0].fn  \n",
    "        norm_layer = block[0].norm  \n",
    "        tokens = norm_layer(tokens)  \n",
    "        qkv = attention_layer.to_qkv(tokens).chunk(3, dim=-1)  \n",
    "        q, k, v = qkv\n",
    "\n",
    "        \n",
    "        attn_weights = (q @ k.transpose(-2, -1)) / q.shape[-1]**0.5  \n",
    "        attn_weights = attn_weights.softmax(dim=-1)  \n",
    "\n",
    "       \n",
    "        entropy = compute_attention_entropy(attn_weights)\n",
    "        attention_entropies.append(entropy)\n",
    "\n",
    "print(\"attention_entropies:\", attention_entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ba0e5f-d47a-4a0c-83ff-a2152ea9d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_norms: [73.81246173381805, 39.30472505092621, 34.22625553607941, 34.91710036993027, 34.91826021671295, 38.420780420303345, 38.29824906587601, 42.031699538230896, 30.326500833034515]\n"
     ]
    }
   ],
   "source": [
    "gradient_norms=[]\n",
    "output = model(x)\n",
    "loss = output.norm() \n",
    "loss.backward()  \n",
    "\n",
    "for i, block in enumerate(blocks):\n",
    "    grad_norm = sum(p.grad.norm().item() for p in block.parameters() if p.grad is not None)\n",
    "    gradient_norms.append(grad_norm)\n",
    "print(\"gradient_norms:\",gradient_norms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc19fca-067b-48ce-91ae-0cabbb73a4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_entropy: 3.9001513263548473\n",
      "T_grad: 28.55012187405655\n",
      "[False False False False False  True  True False False]\n",
      "prune: entropy < 3.900151 or grad < 28.550122\n",
      "prune block: [5, 6]\n"
     ]
    }
   ],
   "source": [
    "k = 1.0  \n",
    "mean_entropy, std_entropy = np.mean(attention_entropies), np.std(attention_entropies)\n",
    "mean_grad, std_grad = np.mean(gradient_norms), np.std(gradient_norms)\n",
    "\n",
    "T_entropy = mean_entropy - k * std_entropy\n",
    "T_grad = mean_grad - k * std_grad\n",
    "print(\"T_entropy:\",T_entropy)\n",
    "print(\"T_grad:\",T_grad)\n",
    "\n",
    "prune_blocks = [i for i in range(len(blocks)) if (attention_entropies[i] < T_entropy or gradient_norms[i] < T_grad)]\n",
    "prune_mask = (attention_entropies < T_entropy) | (gradient_norms < T_grad)\n",
    "print(prune_mask)\n",
    "print(f\"prune: entropy < {T_entropy:.6f} or grad < {T_grad:.6f}\")\n",
    "print(f\"prune block: {prune_blocks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f567472-abd7-45df-a62c-38fbaf45417d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
